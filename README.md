<div align="center">
  <img src="https://readme-typing-svg.herokuapp.com?color=%230070FF&size=32&center=true&vCenter=true&width=600&height=50&lines=Adventure+Works+Project&font=Arial+Black" alt="Headline" />
</div>




 
 <div align=center>
         <a href="https://imgbb.com/"><img src="https://i.ibb.co/b5Ry5S8h/Github-Image.gif" alt="Github-Image" border="0"></a>
  </div>


<h1 align="center">ğŸŒŸ  ABOUT THIS REPOSITORY ğŸŒŸ </h1>

<p align="center" style="display: flex; justify-content: center; gap: 20px;">
  <a href="https://ibb.co/RpyzfdcF">
    <img src="https://i.ibb.co/Z6mW57xj/Dashboard.jpg" alt="Dashboard" width="400" />
  </a>
  <a href="https://ibb.co/qLfNMHxQ">
    <img src="https://i.ibb.co/8nprDyXZ/page-2.jpg" alt="Page-2" width="400" />
  </a>
</p>

ğŸ’¡ **_Key things Learn_**


      1. Data Ingestion: 
          âœ… Extract customer and sales data from an on-premises SQL database.
          âœ… Load the data into Azure Data Lake Storage (ADLS) using Azure Data Factory (ADF).

      2. Data Transformation:
          âœ… Use Azure Databricks to clean and transform the data.
          âœ… Organize the data into Bronze, Silver, and Gold layers for raw, cleansed, and aggregated data respectively.
      
      3. Data Loading and Reporting:
          âœ… Load the transformed data into Azure Synapse Analytics.
          âœ… Build a Power BI dashboard to visualize the data, allowing stakeholders to explore sales and demographic insights.
      
      4. Automation:
          âœ… Schedule the pipeline to run daily, ensuring that the data and reports are always up-to-date.

ğŸ”¥ **_Tech Stack & Tools_**


    - Azure Data Factory (ADF): For orchestrating data movement and transformation.
    - Azure Data Lake Storage (ADLS): For storing raw and processed data.
    - Azure Databricks: For data transformation and processing.
    - Azure Synapse Analytics: For data warehousing and SQL-based analytics.
    - Power BI: For data visualization and reporting.
    - Azure Key Vault: For securely managing credentials and secrets.
    - SQL Server (On-Premises): Source of customer and sales data.

  
  ğŸ¯ **_Goals_**

    ğŸ“š Learn Data Engineering Concepts
    ğŸ§¹ Data Cleaning and Preprocessing
    ğŸ”„ Data Transformation using PySpark
    ğŸ“Š Getting Data-Driven Decisions

ğŸ“Œ **_How to Use ?_**

    
    Prerequisites
                                                                                  
                âœ… An Azure account with sufficient credits.
                âœ… Access to an on-premises SQL Server database.

    Step 1ï¸âƒ£: Azure Environment Setup
    
              1. Create Resource Group: Set up a new resource group in Azure.
              2. Provision Services:
                 - Create an Azure Data Factory instance.
                 - Set up Azure Data Lake Storage with `bronze`, `silver`, and `gold` containers.
                 - Set up an Azure Databricks workspace and Synapse Analytics workspace.
                 - Configure Azure Key Vault for secret management.
    
    Step 2ï¸âƒ£: Data Ingestion
    
              1. Set up SQL Server: Install SQL Server and SQL Server Management Studio (SSMS). Restore the AdventureWorks database.
              2. Ingest Data with ADF: Create pipelines in ADF to copy data from SQL Server to the `bronze` layer in ADLS.
    
    Step 3ï¸âƒ£: Data Transformation
    
              1. Mount Data Lake in Databricks: Configure Databricks to access ADLS.
              2. Transform Data: Use Databricks notebooks to clean and aggregate the data, 
                 moving it from `bronze` to `silver` and then to `gold`.
    
    Step 4ï¸âƒ£: Data Loading and Reporting
    
              1. Load Data into Synapse: Set up a Synapse SQL pool and load the `gold` data for analysis.
              2. Create Power BI Dashboard: Connect Power BI to Synapse and create visualizations based on business requirements.
    
    Step 5ï¸âƒ£: Automation and Monitoring
    
              1. Schedule Pipelines: Use ADF to schedule the data pipelines to run daily.
              2. Monitor Pipeline Runs: Use the monitoring tools in ADF and Synapse to ensure successful pipeline execution.
    
    Step 6ï¸âƒ£: Security and Governance
    
              1. Manage Access: Set up role-based access control (RBAC) using Azure Entra ID (formerly Active Directory).
    
    Step 7ï¸âƒ£: End-to-End Testing
    
              1. Trigger and Test Pipelines: Insert new records into the SQL database and verify 
                 that the entire pipeline runs successfully,updating the Power BI dashboard.

ğŸ“¬ **_Contact & Connect_**

      ğŸ‘¤ GitHub Profile:
      ğŸ’¼ Portfolio Website: Pending
      ğŸ“§ Email: ushanloshitha@gmail.com

<p align="center">
  <a href="https://git.io/typing-svg">
    <img src="https://readme-typing-svg.demolab.com?font=Arial+Black&letterSpacing=8px&pause=1000&color=CCD713&background=FF306200&center=true&vCenter=true&width=435&lines=%F0%9F%9A%80+Good+Luck++!+%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB%E2%9C%A8" alt="Typing SVG" />
  </a>
</p>
  
